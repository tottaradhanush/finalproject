{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb47dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "hospital_data = pd.read_csv(\"hospital_admissions.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d984b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResidentDate_year  ResidentDate_month  ResidentDate_day ResidentDate\n",
      "0               2017                   3                21   2017-03-21\n",
      "1               2017                   3                21   2017-03-21\n",
      "2               2017                   3                21   2017-03-21\n",
      "3               2017                   3                21   2017-03-21\n",
      "4               2017                   3                21   2017-03-21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hospital_data['ResidentDate'] = pd.to_datetime(\n",
    "    hospital_data.rename(columns={\n",
    "        'ResidentDate_year': 'year',\n",
    "        'ResidentDate_month': 'month',\n",
    "        'ResidentDate_day': 'day'\n",
    "    })[['year', 'month', 'day']]\n",
    ")\n",
    "\n",
    "# Check if the date looks correct\n",
    "print(hospital_data[['ResidentDate_year', 'ResidentDate_month', 'ResidentDate_day', 'ResidentDate']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a52ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# CONFIG\n",
    "LAT = 13.0827\n",
    "LON = 80.2707\n",
    "START_DATE = \"2017-03-21\"\n",
    "END_DATE = \"2022-03-20\"\n",
    "API_KEY = '8TEpIGk3AuzzHb0vNIBlWsfq0aeSp6H9' \n",
    "\n",
    "# Fetch Weather from Open-Meteo\n",
    "def fetch_weather(start_date, end_date):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        'latitude': LAT,\n",
    "        'longitude': LON,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum',\n",
    "        'timezone': 'Asia/Kolkata'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame({\n",
    "        'ResidentDate': pd.to_datetime(data['daily']['time']).date,\n",
    "        'temperature_max': data['daily']['temperature_2m_max'],\n",
    "        'temperature_min': data['daily']['temperature_2m_min'],\n",
    "        'precipitation': data['daily']['precipitation_sum']\n",
    "    })\n",
    "\n",
    "# Fetch Holidays using Calendarific\n",
    "def fetch_holidays(year, api_key):\n",
    "    url = \"https://calendarific.com/api/v2/holidays\"\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'country': 'IN',\n",
    "        'year': year,\n",
    "        'location': 'Tamil Nadu',\n",
    "    }\n",
    "    response = requests.get(url, params=params).json()\n",
    "    holidays = []\n",
    "    for item in response['response']['holidays']:\n",
    "        holidays.append({\n",
    "            'ResidentDate': pd.to_datetime(item['date']['iso']).date(),\n",
    "            'event_type': 'Holiday'\n",
    "        })\n",
    "    return pd.DataFrame(holidays)\n",
    "\n",
    "# Covid Waves\n",
    "def generate_covid_waves():\n",
    "    covid_periods = [\n",
    "        ('2020-03-20', '2020-06-30'),\n",
    "        ('2021-04-15', '2021-06-15'),\n",
    "        ('2022-01-01', '2022-03-01')\n",
    "    ]\n",
    "    covid_list = []\n",
    "    for start, end in covid_periods:\n",
    "        date_range = pd.date_range(start, end)\n",
    "        covid_list.extend([{'ResidentDate': d.date(), 'event_type': 'Covid_Wave'} for d in date_range])\n",
    "    return pd.DataFrame(covid_list)\n",
    "\n",
    "# Placeholder for Disasters, Elections, Festivals\n",
    "def fetch_placeholder_events():\n",
    "    sample_events = [\n",
    "        {'ResidentDate': pd.to_datetime('2018-11-15').date(), 'event_type': 'Disaster'},\n",
    "        {'ResidentDate': pd.to_datetime('2019-05-23').date(), 'event_type': 'Election'},\n",
    "        {'ResidentDate': pd.to_datetime('2023-01-14').date(), 'event_type': 'Festival'},\n",
    "    ]\n",
    "    return pd.DataFrame(sample_events)\n",
    "\n",
    "# Merge all events with priority logic\n",
    "def merge_all_events(start_date, end_date, api_key):\n",
    "    weather = fetch_weather(start_date, end_date)\n",
    "\n",
    "    holiday_frames = [fetch_holidays(year, api_key) for year in range(\n",
    "        pd.to_datetime(start_date).year, pd.to_datetime(end_date).year + 1)]\n",
    "    holidays = pd.concat(holiday_frames, ignore_index=True)\n",
    "\n",
    "    covid = generate_covid_waves()\n",
    "    manual_events = fetch_placeholder_events()\n",
    "\n",
    "    # Mark Sundays\n",
    "    date_range = pd.DataFrame({'ResidentDate': pd.date_range(start_date, end_date)})\n",
    "    date_range['weekday'] = date_range['ResidentDate'].dt.weekday\n",
    "    sundays = date_range[date_range['weekday'] == 6][['ResidentDate']].copy()\n",
    "    sundays['event_type'] = 'Sunday'\n",
    "    sundays['ResidentDate'] = sundays['ResidentDate'].dt.date\n",
    "\n",
    "    # Combine all event types\n",
    "    all_events = pd.concat([manual_events, holidays, covid, sundays], ignore_index=True)\n",
    "\n",
    "    # Priority map\n",
    "    priority_map = {\n",
    "        'Disaster': 1,\n",
    "        'Election': 2,\n",
    "        'Festival': 3,\n",
    "        'Holiday': 4,\n",
    "        'Covid_Wave': 5,\n",
    "        'Sunday': 6\n",
    "    }\n",
    "    all_events['priority'] = all_events['event_type'].map(priority_map)\n",
    "\n",
    "    # Keep only highest priority per date\n",
    "    all_events = all_events.sort_values(['ResidentDate', 'priority']).drop_duplicates('ResidentDate')\n",
    "\n",
    "    # Merge with weather\n",
    "    merged = pd.merge(weather, all_events[['ResidentDate', 'event_type']], on='ResidentDate', how='left')\n",
    "    merged['event_type'] = merged['event_type'].fillna('None')\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Merge with Hospital Data\n",
    "def merge_with_hospital_data(hospital_data, external_factors):\n",
    "    # Rename for datetime creation\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'ResidentDate_year': 'year',\n",
    "        'ResidentDate_month': 'month',\n",
    "        'ResidentDate_day': 'day'\n",
    "    })\n",
    "\n",
    "    # Construct ResidentDate\n",
    "    hospital_data['ResidentDate'] = pd.to_datetime(\n",
    "        hospital_data[['year', 'month', 'day']]\n",
    "    ).dt.date\n",
    "\n",
    "    # Rename back\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'year': 'ResidentDate_year',\n",
    "        'month': 'ResidentDate_month',\n",
    "        'day': 'ResidentDate_day'\n",
    "    })\n",
    "\n",
    "    # Merge external factors\n",
    "    merged_data = pd.merge(hospital_data, external_factors, on='ResidentDate', how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Usage Example\n",
    "# Replace this with your actual hospital dataset CSV\n",
    "hospital_data = pd.read_csv('hospital_admissions.csv')\n",
    "\n",
    "# Fetch enriched external factors\n",
    "external_factors = merge_all_events(START_DATE, END_DATE, API_KEY)\n",
    "\n",
    "# Merge the two\n",
    "merged_hospital_data = merge_with_hospital_data(hospital_data, external_factors)\n",
    "\n",
    "# Save both original and enriched\n",
    "hospital_data.to_csv('original_hospital_data.csv', index=False)\n",
    "merged_hospital_data.to_csv('hospital_data_with_external_factors.csv', index=False)\n",
    "\n",
    "print(\"✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ec72c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasua\\AppData\\Local\\Temp\\ipykernel_24036\\765614079.py:65: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['ResidentDate'] = pd.to_datetime(df['ResidentDate']).dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# CONFIG\n",
    "LAT = 13.0827\n",
    "LON = 80.2707\n",
    "START_DATE = \"2017-03-21\"\n",
    "END_DATE = \"2022-03-20\"\n",
    "API_KEY = '8TEpIGk3AuzzHb0vNIBlWsfq0aeSp6H9'  # Calendarific API Key\n",
    "\n",
    "# Fetch Weather from Open-Meteo\n",
    "def fetch_weather(start_date, end_date):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        'latitude': LAT,\n",
    "        'longitude': LON,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum',\n",
    "        'timezone': 'Asia/Kolkata'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame({\n",
    "        'ResidentDate': pd.to_datetime(data['daily']['time']).date,\n",
    "        'temperature_max': data['daily']['temperature_2m_max'],\n",
    "        'temperature_min': data['daily']['temperature_2m_min'],\n",
    "        'precipitation': data['daily']['precipitation_sum']\n",
    "    })\n",
    "\n",
    "# Fetch Holidays using Calendarific\n",
    "def fetch_holidays(year, api_key):\n",
    "    url = \"https://calendarific.com/api/v2/holidays\"\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'country': 'IN',\n",
    "        'year': year,\n",
    "        'location': 'Tamil Nadu',\n",
    "    }\n",
    "    response = requests.get(url, params=params).json()\n",
    "    holidays = []\n",
    "    for item in response['response']['holidays']:\n",
    "        holidays.append({\n",
    "            'ResidentDate': pd.to_datetime(item['date']['iso']).date(),\n",
    "            'event_type': 'Holiday'\n",
    "        })\n",
    "    return pd.DataFrame(holidays)\n",
    "\n",
    "# Covid Waves\n",
    "def generate_covid_waves():\n",
    "    covid_periods = [\n",
    "        ('2020-03-20', '2020-06-30'),\n",
    "        ('2021-04-15', '2021-06-15'),\n",
    "        ('2022-01-01', '2022-03-01')\n",
    "    ]\n",
    "    covid_list = []\n",
    "    for start, end in covid_periods:\n",
    "        date_range = pd.date_range(start, end)\n",
    "        covid_list.extend([{'ResidentDate': d.date(), 'event_type': 'Covid_Wave'} for d in date_range])\n",
    "    return pd.DataFrame(covid_list)\n",
    "\n",
    "# Load Disaster Events from CSV\n",
    "def fetch_disaster_events():\n",
    "    df = pd.read_csv('disaster_data_chennai_2016_2022_gemini.csv')\n",
    "    df['ResidentDate'] = pd.to_datetime(df['ResidentDate']).dt.date\n",
    "    return df\n",
    "\n",
    "# Merge all events with priority logic\n",
    "def merge_all_events(start_date, end_date, api_key):\n",
    "    weather = fetch_weather(start_date, end_date)\n",
    "\n",
    "    holiday_frames = [fetch_holidays(year, api_key) for year in range(\n",
    "        pd.to_datetime(start_date).year, pd.to_datetime(end_date).year + 1)]\n",
    "    holidays = pd.concat(holiday_frames, ignore_index=True)\n",
    "\n",
    "    covid = generate_covid_waves()\n",
    "    disaster_events = fetch_disaster_events()\n",
    "\n",
    "    # Mark Sundays\n",
    "    date_range = pd.DataFrame({'ResidentDate': pd.date_range(start_date, end_date)})\n",
    "    date_range['weekday'] = date_range['ResidentDate'].dt.weekday\n",
    "    sundays = date_range[date_range['weekday'] == 6][['ResidentDate']].copy()\n",
    "    sundays['event_type'] = 'Sunday'\n",
    "    sundays['ResidentDate'] = sundays['ResidentDate'].dt.date\n",
    "\n",
    "    # Combine all event types\n",
    "    all_events = pd.concat([disaster_events, holidays, covid, sundays], ignore_index=True)\n",
    "\n",
    "    # Priority Map\n",
    "    priority_map = {\n",
    "        'Cyclone Vardah': 1,\n",
    "        'Heavy Rains & Flooding': 1,\n",
    "        'Disaster': 1,\n",
    "        'Election': 2,\n",
    "        'Festival': 3,\n",
    "        'Holiday': 4,\n",
    "        'Covid_Wave': 5,\n",
    "        'Sunday': 6\n",
    "    }\n",
    "    all_events['priority'] = all_events['event_type'].map(lambda x: priority_map.get(x, 7))\n",
    "\n",
    "    # Keep highest priority event for each date\n",
    "    all_events = all_events.sort_values(['ResidentDate', 'priority']).drop_duplicates('ResidentDate')\n",
    "\n",
    "    # Merge with weather data\n",
    "    merged = pd.merge(weather, all_events[['ResidentDate', 'event_type']], on='ResidentDate', how='left')\n",
    "    merged['event_type'] = merged['event_type'].fillna('None')\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Merge with Hospital Data\n",
    "def merge_with_hospital_data(hospital_data, external_factors):\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'ResidentDate_year': 'year',\n",
    "        'ResidentDate_month': 'month',\n",
    "        'ResidentDate_day': 'day'\n",
    "    })\n",
    "\n",
    "    hospital_data['ResidentDate'] = pd.to_datetime(\n",
    "        hospital_data[['year', 'month', 'day']]\n",
    "    ).dt.date\n",
    "\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'year': 'ResidentDate_year',\n",
    "        'month': 'ResidentDate_month',\n",
    "        'day': 'ResidentDate_day'\n",
    "    })\n",
    "\n",
    "    merged_data = pd.merge(hospital_data, external_factors, on='ResidentDate', how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Usage Example\n",
    "hospital_data = pd.read_csv('hospital_admissions.csv')\n",
    "\n",
    "# Fetch enriched external factors\n",
    "external_factors = merge_all_events(START_DATE, END_DATE, API_KEY)\n",
    "\n",
    "# Merge hospital data with external factors\n",
    "merged_hospital_data = merge_with_hospital_data(hospital_data, external_factors)\n",
    "\n",
    "# Save to CSV\n",
    "hospital_data.to_csv('original_hospital_data.csv', index=False)\n",
    "merged_hospital_data.to_csv('hospital_data_with_external_factors.csv', index=False)\n",
    "\n",
    "print(\"✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4170b459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasua\\AppData\\Local\\Temp\\ipykernel_24036\\1624870305.py:65: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['ResidentDate'] = pd.to_datetime(df['ResidentDate']).dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# CONFIG\n",
    "LAT = 13.0827\n",
    "LON = 80.2707\n",
    "START_DATE = \"2017-03-21\"\n",
    "END_DATE = \"2022-03-20\"\n",
    "API_KEY = '8TEpIGk3AuzzHb0vNIBlWsfq0aeSp6H9'  # Calendarific API Key\n",
    "\n",
    "# Fetch Weather from Open-Meteo\n",
    "def fetch_weather(start_date, end_date):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        'latitude': LAT,\n",
    "        'longitude': LON,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum',\n",
    "        'timezone': 'Asia/Kolkata'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame({\n",
    "        'ResidentDate': pd.to_datetime(data['daily']['time']).date,\n",
    "        'temperature_max': data['daily']['temperature_2m_max'],\n",
    "        'temperature_min': data['daily']['temperature_2m_min'],\n",
    "        'precipitation': data['daily']['precipitation_sum']\n",
    "    })\n",
    "\n",
    "# Fetch Holidays using Calendarific\n",
    "def fetch_holidays(year, api_key):\n",
    "    url = \"https://calendarific.com/api/v2/holidays\"\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'country': 'IN',\n",
    "        'year': year,\n",
    "        'location': 'Tamil Nadu',\n",
    "    }\n",
    "    response = requests.get(url, params=params).json()\n",
    "    holidays = []\n",
    "    for item in response['response']['holidays']:\n",
    "        holidays.append({\n",
    "            'ResidentDate': pd.to_datetime(item['date']['iso']).date(),\n",
    "            'event_type': 'Holiday'\n",
    "        })\n",
    "    return pd.DataFrame(holidays)\n",
    "\n",
    "# Covid Waves — returns a dataframe\n",
    "def generate_covid_waves():\n",
    "    covid_periods = [\n",
    "        ('2020-03-20', '2020-06-30'),\n",
    "        ('2021-04-15', '2021-06-15'),\n",
    "        ('2022-01-01', '2022-03-01')\n",
    "    ]\n",
    "    covid_list = []\n",
    "    for start, end in covid_periods:\n",
    "        date_range = pd.date_range(start, end)\n",
    "        covid_list.extend([{'ResidentDate': d.date(), 'pandemic': 'Covid_Wave'} for d in date_range])\n",
    "    return pd.DataFrame(covid_list)\n",
    "\n",
    "# Disaster Events — returns a dataframe\n",
    "def fetch_disaster_events():\n",
    "    df = pd.read_csv('disaster_data_chennai_2016_2022_gemini.csv')\n",
    "    df['ResidentDate'] = pd.to_datetime(df['ResidentDate']).dt.date\n",
    "    df = df[['ResidentDate', 'event_type']]\n",
    "    df = df.rename(columns={'event_type': 'disaster'})\n",
    "    return df\n",
    "\n",
    "# Merge all external features\n",
    "def merge_all_events(start_date, end_date, api_key):\n",
    "    weather = fetch_weather(start_date, end_date)\n",
    "\n",
    "    # Fetch holidays\n",
    "    holiday_frames = [fetch_holidays(year, api_key) for year in range(\n",
    "        pd.to_datetime(start_date).year, pd.to_datetime(end_date).year + 1)]\n",
    "    holidays = pd.concat(holiday_frames, ignore_index=True)\n",
    "\n",
    "    # Fetch pandemic and disaster data\n",
    "    covid = generate_covid_waves()\n",
    "    disasters = fetch_disaster_events()\n",
    "\n",
    "    # Sundays\n",
    "    date_range = pd.DataFrame({'ResidentDate': pd.date_range(start_date, end_date)})\n",
    "    date_range['weekday'] = date_range['ResidentDate'].dt.weekday\n",
    "    sundays = date_range[date_range['weekday'] == 6][['ResidentDate']].copy()\n",
    "    sundays['event_type'] = 'Sunday'\n",
    "    sundays['ResidentDate'] = sundays['ResidentDate'].dt.date\n",
    "\n",
    "    # Combine general event types (Holiday + Sunday)\n",
    "    general_events = pd.concat([holidays, sundays], ignore_index=True)\n",
    "    general_events = general_events.drop_duplicates(subset=['ResidentDate'])\n",
    "\n",
    "    # Merge all on ResidentDate\n",
    "    merged = pd.merge(weather, general_events, on='ResidentDate', how='left')\n",
    "    merged = pd.merge(merged, covid, on='ResidentDate', how='left')\n",
    "    merged = pd.merge(merged, disasters, on='ResidentDate', how='left')\n",
    "\n",
    "    # Fill missing\n",
    "    merged['event_type'] = merged['event_type'].fillna('None')\n",
    "    merged['pandemic'] = merged['pandemic'].fillna('None')\n",
    "    merged['disaster'] = merged['disaster'].fillna('None')\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Merge with Hospital Data\n",
    "def merge_with_hospital_data(hospital_data, external_factors):\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'ResidentDate_year': 'year',\n",
    "        'ResidentDate_month': 'month',\n",
    "        'ResidentDate_day': 'day'\n",
    "    })\n",
    "\n",
    "    hospital_data['ResidentDate'] = pd.to_datetime(\n",
    "        hospital_data[['year', 'month', 'day']]\n",
    "    ).dt.date\n",
    "\n",
    "    hospital_data = hospital_data.rename(columns={\n",
    "        'year': 'ResidentDate_year',\n",
    "        'month': 'ResidentDate_month',\n",
    "        'day': 'ResidentDate_day'\n",
    "    })\n",
    "\n",
    "    merged_data = pd.merge(hospital_data, external_factors, on='ResidentDate', how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Usage Example\n",
    "hospital_data = pd.read_csv('hospital_admissions.csv')\n",
    "\n",
    "# Fetch enriched external factors\n",
    "external_factors = merge_all_events(START_DATE, END_DATE, API_KEY)\n",
    "\n",
    "# Merge hospital data with external factors\n",
    "merged_hospital_data = merge_with_hospital_data(hospital_data, external_factors)\n",
    "\n",
    "# Save to CSV\n",
    "hospital_data.to_csv('original_hospital_data.csv', index=False)\n",
    "merged_hospital_data.to_csv('hospital_data_with_external_factors.csv', index=False)\n",
    "\n",
    "print(\"✅ Saved: 'original_hospital_data.csv' and 'hospital_data_with_external_factors.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0b3f7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (775136401.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    pandemic_data.to_csv('pandemic_data.csv', index=False)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wikipedia URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_epidemics_and_pandemics\"\n",
    "\n",
    "# Read all tables from the page\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Combine all tables (some are grouped by century)\n",
    "pandemic_data = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "# Display a preview\n",
    "pandemic_data.to_csv('pandemic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d18e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\vasua\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
